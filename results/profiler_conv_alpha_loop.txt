not verified
Wrote profile results to verifier.py.lprof
Timer unit: 1e-06 s

Total time: 0.1527 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: compute_weight_matrix at line 145

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   145                                               @profile
   146                                               def compute_weight_matrix(self, inp_shape):
   147                                                   
   148         2          1.0      0.5      0.0          @profile
   149         2         54.0     27.0      0.0          def get_weight(inp_shape, conv_row, conv_col, kernel):
   150                                                       temp = torch.zeros(inp_shape)
   151                                                       end_row = conv_row + kernel.shape[1]
   152                                                       end_col = conv_col + kernel.shape[2]
   153                                                       temp[:, conv_row:end_row, conv_col:end_col] = kernel
   154                                                       return temp
   155                                                   
   156         2          0.0      0.0      0.0          @profile
   157         2         57.0     28.5      0.0          def get_weight_matrix(conv, inp_shape):
   158                                                       #TODO: Improve efficiency. Remove loops
   159                                                       kernel = conv.weight.data.detach()
   160                                                       C_out, C_in, K_h, K_w = kernel.shape
   161                                                       N_in, C_in, H_i, W_i = inp_shape
   162                                                       H_o = ((inp_shape[-2] + conv.padding[-2] + conv.padding[-2] - conv.kernel_size[-2]) // conv.stride[-2] + 1)
   163                                                       W_o = ((inp_shape[-1] + conv.padding[-1] + conv.padding[-1] - conv.kernel_size[-1]) // conv.stride[-1] + 1)
   164                                                       out_shape = N_in, C_out, H_o, W_o
   165                                           
   166                                                       H_grd, W_grd = H_o, H_i
   167                                                       H_blk, W_blk = W_o, W_i
   168                                           
   169                                                       W_conv = torch.zeros((C_out, H_grd, H_blk, C_in, W_grd, W_blk), dtype=torch.double)
   170                                           
   171                                                       for c in range(C_out):
   172                                                           for i in range(H_o):
   173                                                               for j in range(W_o):
   174                                                                   padded_H_i, padded_W_i = H_i + 2 * conv.padding[0], W_i + 2 * conv.padding[1]
   175                                                                   conv_row, conv_col = i * conv.stride[0], j * conv.stride[1]
   176                                                                   if conv_row >= padded_H_i | conv_col >= padded_W_i:
   177                                                                       continue
   178                                                                   temp_weight = get_weight((C_in, padded_H_i, padded_W_i), conv_row, conv_col, kernel[c])
   179                                                                   W_conv[c, i, j] = temp_weight[:, conv.padding[0] : H_i+conv.padding[0], conv.padding[1] : W_i + conv.padding[1]]
   180                                           
   181                                                       B_conv = conv.bias.data.detach()
   182                                                       B_conv = torch.ones(H_o*W_o, C_out) * B_conv
   183                                                       B_conv = B_conv.t()
   184                                           
   185                                                       return W_conv, B_conv, out_shape
   186                                                   
   187                                                   # conv = nn.Conv2d(1, 16, kernel_size=(3,3), padding=(2, 2), stride=(2, 2))
   188                                                   # conv.double()
   189                                                   # # conv.bias.data = torch.zeros_like(conv.bias)
   190                                                   # inp_shape = (1, 1, 28, 28)
   191                                           
   192         2     152520.0  76260.0     99.9          W, B, out_shape = get_weight_matrix(self.layer, inp_shape)
   193                                           
   194         2         24.0     12.0      0.0          W = torch.flatten(W, start_dim=0, end_dim=2)
   195         2          4.0      2.0      0.0          W = torch.flatten(W, start_dim=1, end_dim=3)
   196                                           
   197         2         38.0     19.0      0.0          B = B.flatten()
   198         2          2.0      1.0      0.0          W.shape[1] == B.shape[0]
   199                                           
   200                                                   # def test_weight(T, B, conv, inp_shape):
   201                                                   #     i = torch.randn(*inp_shape, dtype = torch.double)
   202                                                   #     out = i.flatten() @ T.t() + B
   203                                                   #     print(torch.allclose(conv(i).flatten(), out.flatten(), atol=1e-06))
   204                                           
   205                                                   # for i in range(100):
   206                                                   #     test_weight(W, B, conv, inp_shape)
   207         2          0.0      0.0      0.0          return W, B, out_shape

Total time: 0.022899 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: get_weight at line 148

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   148                                                   @profile
   149                                                   def get_weight(inp_shape, conv_row, conv_col, kernel):
   150      4096       5733.0      1.4     25.0              temp = torch.zeros(inp_shape)
   151      4096       1070.0      0.3      4.7              end_row = conv_row + kernel.shape[1]
   152      4096        845.0      0.2      3.7              end_col = conv_col + kernel.shape[2]
   153      4096      14662.0      3.6     64.0              temp[:, conv_row:end_row, conv_col:end_col] = kernel
   154      4096        589.0      0.1      2.6              return temp

Total time: 0.073318 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: get_weight_matrix at line 156

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   156                                                   @profile
   157                                                   def get_weight_matrix(conv, inp_shape):
   158                                                       #TODO: Improve efficiency. Remove loops
   159         1         10.0     10.0      0.0              kernel = conv.weight.data.detach()
   160         1          1.0      1.0      0.0              C_out, C_in, K_h, K_w = kernel.shape
   161         1          0.0      0.0      0.0              N_in, C_in, H_i, W_i = inp_shape
   162         1          1.0      1.0      0.0              H_o = ((inp_shape[-2] + conv.padding[-2] + conv.padding[-2] - conv.kernel_size[-2]) // conv.stride[-2] + 1)
   163         1          0.0      0.0      0.0              W_o = ((inp_shape[-1] + conv.padding[-1] + conv.padding[-1] - conv.kernel_size[-1]) // conv.stride[-1] + 1)
   164         1          0.0      0.0      0.0              out_shape = N_in, C_out, H_o, W_o
   165                                           
   166         1          0.0      0.0      0.0              H_grd, W_grd = H_o, H_i
   167         1          0.0      0.0      0.0              H_blk, W_blk = W_o, W_i
   168                                           
   169         1       3386.0   3386.0      4.6              W_conv = torch.zeros((C_out, H_grd, H_blk, C_in, W_grd, W_blk), dtype=torch.double)
   170                                           
   171        65         15.0      0.2      0.0              for c in range(C_out):
   172       576         71.0      0.1      0.1                  for i in range(H_o):
   173      4608        822.0      0.2      1.1                      for j in range(W_o):
   174      4096       1183.0      0.3      1.6                          padded_H_i, padded_W_i = H_i + 2 * conv.padding[0], W_i + 2 * conv.padding[1]
   175      4096        989.0      0.2      1.3                          conv_row, conv_col = i * conv.stride[0], j * conv.stride[1]
   176      4096        770.0      0.2      1.1                          if conv_row >= padded_H_i | conv_col >= padded_W_i:
   177                                                                       continue
   178      4096      34894.0      8.5     47.6                          temp_weight = get_weight((C_in, padded_H_i, padded_W_i), conv_row, conv_col, kernel[c])
   179      4096      31120.0      7.6     42.4                          W_conv[c, i, j] = temp_weight[:, conv.padding[0] : H_i+conv.padding[0], conv.padding[1] : W_i + conv.padding[1]]
   180                                           
   181         1         14.0     14.0      0.0              B_conv = conv.bias.data.detach()
   182         1         36.0     36.0      0.0              B_conv = torch.ones(H_o*W_o, C_out) * B_conv
   183         1          6.0      6.0      0.0              B_conv = B_conv.t()
   184                                           
   185         1          0.0      0.0      0.0              return W_conv, B_conv, out_shape

Total time: 1.54037 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: compute_bound at line 209

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   209                                               @profile 
   210                                               def compute_bound(self, bounds: DpBounds):
   211        22         35.0      1.6      0.0          if self.inp_shape != None and self.inp_shape == bounds.shape:
   212        20          6.0      0.3      0.0              r = self.constraints.lr
   213        20          4.0      0.2      0.0              o = self.constraints.lo
   214                                                   else:
   215         2          3.0      1.5      0.0              self.inp_shape = bounds.shape
   216         2     152711.0  76355.5      9.9              r, o, out_shape = self.compute_weight_matrix(bounds.shape)
   217         2          8.0      4.0      0.0              self.constraints = DpConstraints(r, r, o, o)
   218         2          0.0      0.0      0.0              self.out_shape = out_shape
   219                                           
   220        22    1387256.0  63057.1     90.1          self.bounds = bounds_mul_constraints(DpConstraints(r.t(), r.t(), o, o), bounds)
   221        22        305.0     13.9      0.0          self.bounds.lb = self.bounds.lb.view(self.out_shape)
   222        22         39.0      1.8      0.0          self.bounds.ub = self.bounds.ub.view(self.out_shape)
   223        22          4.0      0.2      0.0          return self.bounds

Total time: 56.4277 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: deeppoly_backsub at line 253

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   253                                           @profile
   254                                           def deeppoly_backsub(dp_layers):
   255        66     223546.0   3387.1      0.4      constraints_acc = dp_layers[-1].constraints.copy()
   256        66        445.0      6.7      0.0      constraints_acc.ur = constraints_acc.ur.t()
   257        66         83.0      1.3      0.0      constraints_acc.lr = constraints_acc.lr.t()
   258        66        228.0      3.5      0.0      logger.debug('[BACKSUBSTITUTION START]')
   259        66    4199690.0  63631.7      7.4      logger.debug(f'Current Layer [{dp_layers[-1].layer}]:\n{str(constraints_acc)}')
   260       451        475.0      1.1      0.0      for i, layer in enumerate(reversed(dp_layers[1:-1])):
   261       385   48561738.0 126134.4     86.1          constraints_acc = layer.backsub(constraints_acc)
   262       385       6470.0     16.8      0.0          logger.debug(f'Layer {len(dp_layers) - 2 - i} [{layer.layer}]:')
   263       385     289251.0    751.3      0.5          logger.debug(str(constraints_acc))
   264                                                   
   265        66        542.0      8.2      0.0      ur = constraints_acc.ur.flatten(0, -2)
   266        66         35.0      0.5      0.0      assert ur.dim() == 2
   267        66        120.0      1.8      0.0      lr = constraints_acc.lr.flatten(0, -2)
   268        66        288.0      4.4      0.0      lb_in = dp_layers[0].bounds.lb.flatten(1)
   269        66        112.0      1.7      0.0      ub_in = dp_layers[0].bounds.ub.flatten(1)
   270        66    1301077.0  19713.3      2.3      b_curr = bounds_mul_constraints(DpConstraints(lr, ur, constraints_acc.lo, constraints_acc.uo), DpBounds(lb_in, ub_in))
   271        66        762.0     11.5      0.0      lb = b_curr.lb.view(dp_layers[-1].bounds.shape)
   272        66        166.0      2.5      0.0      ub = b_curr.ub.view(dp_layers[-1].bounds.shape)
   273        66        192.0      2.9      0.0      logger.debug(f'Input Layer:')
   274        66    1840443.0  27885.5      3.3      logger.debug(str(constraints_acc))
   275        66         78.0      1.2      0.0      logger.debug('[BACKSUBSTITUTION END]')
   276        66       1938.0     29.4      0.0      return DpBounds(lb, ub)

Total time: 61.01 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: propagate_sample at line 278

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   278                                           @profile
   279                                           def propagate_sample(model, x, eps, le_layer=None, min_val=0, max_val=1, layers=None):
   280        11        491.0     44.6      0.0      bounds = get_input_bounds(x, eps, min_val, max_val)
   281        11         25.0      2.3      0.0      input_layer = DpInput(bounds)
   282        11         11.0      1.0      0.0      dp_layers = [input_layer] if layers == None else layers
   283        11        369.0     33.5      0.0      log_layer_bounds(logger, input_layer, 'Input Layer')
   284       143        180.0      1.3      0.0      for i, layer in enumerate(model):
   285       132         18.0      0.1      0.0          dp_layer = None
   286       132         43.0      0.3      0.0          if layers != None:
   287       120         44.0      0.4      0.0              dp_layer = dp_layers[i + 1] # i + 1 as the first element is DpInput
   288       120    3958533.0  32987.8      6.5              dp_layer.compute_bound(dp_layers[i].bounds)
   289        12         10.0      0.8      0.0          elif isinstance(layer, nn.Flatten):
   290         1          2.0      2.0      0.0              dp_layer = DpFlatten(layer)
   291         1         47.0     47.0      0.0              dp_layer.compute_bound(dp_layers[i].bounds)
   292        11          5.0      0.5      0.0          elif isinstance(layer, nn.Linear):
   293         4         73.0     18.2      0.0              dp_layer = DpLinear(layer)
   294         4       3627.0    906.8      0.0              dp_layer.compute_bound(dp_layers[i].bounds)
   295         7          2.0      0.3      0.0          elif isinstance(layer, nn.ReLU):
   296         5         14.0      2.8      0.0              dp_layer = DpRelu(layer, False)
   297         5     225239.0  45047.8      0.4              dp_layer.compute_bound(dp_layers[i].bounds)
   298         2          1.0      0.5      0.0          elif isinstance(layer, nn.LeakyReLU):
   299                                                       dp_layer = DpRelu(layer)
   300                                                       dp_layer.compute_bound(dp_layers[i].bounds)
   301         2          0.0      0.0      0.0          elif isinstance(layer, nn.Conv2d):
   302         2          4.0      2.0      0.0              dp_layer = DpConv(layer)
   303         2     299294.0 149647.0      0.5              dp_layer.compute_bound(dp_layers[i].bounds)
   304                                           
   305                                                   # Uncomment this line after optimization of DpConv.compute_bound is complete
   306                                                   # dp_layer.compute_bound(dp_layers[i].bounds)
   307                                                   
   308       132         73.0      0.6      0.0          if layers == None:
   309        12          6.0      0.5      0.0              dp_layers.append(dp_layer)
   310                                                   
   311                                                   # Backsubstitution is called on the layer before the ReLU
   312       132        346.0      2.6      0.0          if not isinstance(layer, nn.Flatten):
   313       121       1317.0     10.9      0.0              if i + 2 <= len(model) and (isinstance(model[i + 1], nn.ReLU) or isinstance(model[i + 1], nn.LeakyReLU)):
   314        55   54826296.0 996841.7     89.9                  dp_layer.bounds = deeppoly_backsub(dp_layers[:i+2]) # i + 2 as the first element is DpInput
   315                                                           
   316       132       5810.0     44.0      0.0          log_layer_bounds(logger, dp_layer, f'Layer {i + 1} [{layer}]')
   317                                           
   318        11          0.0      0.0      0.0      if le_layer is not None:
   319        11          0.0      0.0      0.0          if layers is None:
   320         1          0.0      0.0      0.0              dp_layers.append(le_layer)
   321         1     150443.0 150443.0      0.2              le_layer.bounds = deeppoly_backsub(dp_layers)
   322                                                   else:
   323        10         62.0      6.2      0.0              dp_layers[-1] = le_layer
   324        10    1537372.0 153737.2      2.5              le_layer.bounds = deeppoly_backsub(dp_layers)
   325        11        207.0     18.8      0.0          log_layer_bounds(logger, le_layer, f'Layer {len(dp_layers) - 1} [{le_layer}]:')
   326                                           
   327        11          1.0      0.1      0.0      return dp_layers

Total time: 103.438 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: certify_sample at line 335

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   335                                           @profile
   336                                           def certify_sample(model, x, y, eps, use_le=True, use_slope_opt=True) -> bool:
   337         1        464.0    464.0      0.0      model.double()
   338         1          2.0      2.0      0.0      x.double()
   339                                           
   340         1          0.0      0.0      0.0      if x.dim() == 3:
   341         1          2.0      2.0      0.0          x = x.unsqueeze(0)
   342                                           
   343         1          0.0      0.0      0.0      if use_le:
   344         1          5.0      5.0      0.0          n_classes = model[-1].out_features
   345         1        166.0    166.0      0.0          le_layer = DiffLayer(y, n_classes)
   346         1    5567096.0    6e+06      5.4          dp_layers = propagate_sample(model, x, eps, le_layer=le_layer)
   347                                               else:
   348                                                   dp_layers = propagate_sample(model, x, eps)
   349                                           
   350         1          1.0      1.0      0.0      bounds = dp_layers[-1].bounds
   351                                           
   352         1         21.0     21.0      0.0      verified = check_postcondition_le(bounds) if use_le else check_postcondition(y, bounds)
   353         1          1.0      1.0      0.0      if verified:
   354                                                   logger.warning(f'Certification Distance: {bounds.get_certification_distance()}')
   355                                                   return True
   356                                               else:
   357         1   97870457.0    1e+08     94.6          verified = certify_with_alphas(model, dp_layers, x, y, eps, use_le) if use_slope_opt else False
   358                                           
   359         1          1.0      1.0      0.0      return verified

Total time: 97.8702 s
File: /Users/ariskoutris/Documents/Reliable and Trustworthy AI/Projects/rtai-project-28/code/deeppoly.py
Function: certify_with_alphas at line 361

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   361                                           @profile
   362                                           def certify_with_alphas(model, dp_layers, x, y, eps, use_le=True):
   363                                               
   364         1        189.0    189.0      0.0      alphas_dict = init_alphas(model, x.shape)
   365         1          0.0      0.0      0.0      if alphas_dict is None:
   366                                                   return False
   367         1          6.0      6.0      0.0      dp_layers = assign_alphas_to_relus(dp_layers, alphas_dict)
   368                                           
   369         1         39.0     39.0      0.0      loss_func = nn.CrossEntropyLoss() 
   370         1         41.0     41.0      0.0      optimizer = torch.optim.Adam([alphas_dict[key].value for key in alphas_dict], lr=2)
   371                                           
   372                                               # Early Stopping Parameters
   373         1          0.0      0.0      0.0      num_epochs = 30
   374         1          0.0      0.0      0.0      min_epochs = 3
   375         1          0.0      0.0      0.0      window_size = 5
   376         1          0.0      0.0      0.0      cd_window = []
   377         1          0.0      0.0      0.0      cd_max = -1000
   378         1          0.0      0.0      0.0      patience = 3
   379         1          0.0      0.0      0.0      pi_window = []
   380                                               
   381        10          4.0      0.4      0.0      for epoch in range(num_epochs):
   382                                                   
   383        10          1.0      0.1      0.0          if use_le:
   384        10        234.0     23.4      0.0              n_classes = model[-1].out_features
   385        10       1136.0    113.6      0.0              le_layer = DiffLayer(y, n_classes)
   386        10   55443768.0    6e+06     56.7              dp_layers = propagate_sample(model, x, eps, le_layer=le_layer, layers=dp_layers)
   387                                                   else:
   388                                                       dp_layers = propagate_sample(model, x, eps, layers=dp_layers)
   389                                                       
   390        10      60622.0   6062.2      0.1          bounds = dp_layers[-1].bounds
   391                                                   
   392        10          3.0      0.3      0.0          if use_le:
   393        10       3885.0    388.5      0.0              loss = torch.sum(-bounds.lb[bounds.lb < 0])
   394                                                   else:
   395                                                       loss = loss_func(bounds.get_loss_tensor(y), torch.tensor(y).view(1))
   396                                                   
   397        10       1649.0    164.9      0.0          optimizer.zero_grad()
   398        10   42348611.0    4e+06     43.3          loss.backward()
   399        10       4936.0    493.6      0.0          optimizer.step()
   400                                                   
   401        60         30.0      0.5      0.0          for alpha_param in alphas_dict.values():
   402        50        229.0      4.6      0.0              alpha_param.value.data.clamp_(alpha_param.lb, alpha_param.ub)
   403                                           
   404        10        494.0     49.4      0.0          verified = check_postcondition_le(bounds) if use_le else check_postcondition(y, bounds)
   405        10         34.0      3.4      0.0          cert_dist = bounds.get_certification_distance()
   406                                                   
   407        10         28.0      2.8      0.0          if verified:
   408                                                       logger.warning(f'Certification Distance: {cert_dist}\n')
   409                                                       return True
   410                                                   
   411        10          5.0      0.5      0.0          if len(cd_window) == window_size:
   412         5         27.0      5.4      0.0              cd_window.pop(0)
   413         5          8.0      1.6      0.0              pi_window.pop(0)
   414                                                       
   415        10          1.0      0.1      0.0          cd_window.append(cert_dist)
   416        10         48.0      4.8      0.0          perc_improvement = (cd_max - cert_dist) / cd_max
   417        10          2.0      0.2      0.0          pi_window.append(perc_improvement)
   418                                                   
   419        10       1022.0    102.2      0.0          cd_mean = np.mean(cd_window)
   420        10        851.0     85.1      0.0          cd_std = np.std(cd_window)
   421        10         13.0      1.3      0.0          in_upper_confidence_bound = cd_mean + 2 * cd_std >= 0
   422                                                   
   423        10         83.0      8.3      0.0          pi_mean = np.mean(pi_window)
   424        10        181.0     18.1      0.0          pi_std = np.std(pi_window)
   425                                                   
   426        10        142.0     14.2      0.0          new_cd_max = np.max(cd_window)
   427        10          3.0      0.3      0.0          if new_cd_max > cd_max:
   428         6          2.0      0.3      0.0              cd_max = new_cd_max
   429         6          1.0      0.2      0.0              patience_counter = patience
   430                                                   else:
   431         4          3.0      0.8      0.0              patience_counter -= 1
   432                                                   
   433        10       1849.0    184.9      0.0          logger.warning(f'Epoch: {epoch} | Certification Distance: {cert_dist:4f} | Mean: {cd_mean:4f} | Std: {cd_std:4f} | Upper Confidence Bound: {cd_mean + 2 * cd_std:4f} | Max: {cd_max:4f} | Patience: {patience_counter} | Percentage Improvement {perc_improvement:4f} | Mean PI {pi_mean:4f} | Std PI: {pi_std:4f}\n')
   434        10          2.0      0.2      0.0          if epoch > min_epochs:
   435         6          3.0      0.5      0.0              if not in_upper_confidence_bound and patience_counter <= 0:
   436         1         29.0     29.0      0.0                  logger.warning(f'Certification Distance: {cert_dist}\n')
   437         1          0.0      0.0      0.0                  return False
   438                                                   
   439                                               return False

